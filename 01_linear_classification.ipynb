{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_linear_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinKahabka/ClIntKahabka/blob/main/01_linear_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX00wg_24_MX"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rR6vwnl9juJ"
      },
      "source": [
        "# we are going to classify a popular breast cancer dataset\n",
        "data, target = datasets.load_breast_cancer(return_X_y=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QQxbG2W9vbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431e3d76-c9af-449b-98ba-cb72dea4b4a2"
      },
      "source": [
        "# data is a matrix of shape (569, 30)\n",
        "# the first number refers to the number of cases or samples while the second\n",
        "# number refers to the number of features from which we try to predict\n",
        "# breast cancer\n",
        "#\n",
        "# please see the documentation @ https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
        "# for more details\n",
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzA2fNFO9wOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76acae3-ecd6-4558-badc-de2401939ed5"
      },
      "source": [
        "# target is a binary vector of size (569,) in which each entry is the label of\n",
        "# each case, either malignant (0) or benign (1).\n",
        "target[:20]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxzrysCAcJ6"
      },
      "source": [
        "# for simplicity we cut the number of features from 30 to just two features\n",
        "data = data[:, :2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-pv9VrSAm1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "36e9a529-fec7-4f4b-ba67-4114ef4fb1f7"
      },
      "source": [
        "# Excercise 1.1\n",
        "# Try to find a linear classifier by hand that can classify the dataset\n",
        "# as good as possible. Let the classification rule be w1 * f1 + w2 * f2 + w3 > 0\n",
        "# where w1, w2 and w3 are the weights to be learnt and f1, f2 are the features.\n",
        "# What accuracy can you reach?\n",
        "best_accuracy = 0\n",
        "best_preds = None\n",
        "\n",
        "for w1 in np.arange(-1, 2, step=0.1):\n",
        "    for w2 in np.arange(-1, 2, step=0.1):\n",
        "        for w3 in np.arange(-40, 40, 1):\n",
        "          preds = (w1 * data[:, 0] + w2 * data[:, 1] + w3 > 0).astype(int)\n",
        "          accuracy = np.mean(preds != target)\n",
        "\n",
        "          if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_preds = (w1, w2, w3)\n",
        "\n",
        "\n",
        "w1, w2 ,w3 = best_preds\n",
        "print(\"Best weights are\")\n",
        "print(best_preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "plt.scatter(data[:, 0], data[:, 1], c=target)\n",
        "x_vals = np.linspace(data[:, 0].min(), data[:, 0].max(), 100)\n",
        "y_vals = - (w1 * x_vals + w3) / w2\n",
        "plt.plot(x_vals, y_vals)\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.title(\"Linear Classifier w. Decision Boundary\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "only integer scalar arrays can be converted to a scalar index",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-57e416c36806>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw3\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Excercise 1.2\n",
        "# Learn the optimal parameters automatically using gradient descent. For the\n",
        "# loss function use a simple squared loss (t - tp)**2 where t is the target\n",
        "# label (either 0 or 1) and tp = w1 * f1 + w2 * f2 + w3 is the predicted label.\n",
        "# What accuracy can you reach? Why is this loss function problematic? Is there\n",
        "# a better alternative?"
      ],
      "metadata": {
        "id": "L1SqYg0oWs9J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}